% !TEX root = ../Thesis.tex
%%
%%  Hochschule f√ºr Technik und Wirtschaft Berlin --  Abschlussarbeit
%%
%% Kapitel 1
%%
%%

\chapter{Introduction} \label{Introduction}


\section{Background and motivation} \label{Background and motivation}
In statistical analysis, bootstrapping is a method used for the derivation of robust estimates of standard errors and confidence intervals. This is applied to estimates such as mean, median, proportion, odds ratio, correlation coefficient or regression coefficient. Developed by Bradley Efron towards the end of the 1970s in "Bootstrap methods: another look at the jackknife" (1979), inspired by the jackknife technique, the bootstrap remains one of the most significant approaches in contemporary statistics, particularly as an alternative to parametric estimates.
The flexibility of this method in addressing uncertainty in estimates, particularly in the context of smaller or non-normally distributed samples, has made it a valuable tool in a range of business domains, including biostatistics, financial analysis and machine learning. This particular area is of outstanding importance for our course.
In this context, the topic of bootstrapping exemplifies the relationship between theoretical concepts and their practical application. This will be demonstrated later in the course through the implementation of clear, yet uninterpretable, results. 


\section{Objectives of the paper}
The objective of this paper is to provide the reader with an insight into the concept of
bootstrapping. To this end, we will first elucidate some pivotal terminology and funda-
mental mathematical principles, with a view to fostering a more nuanced comprehension.
Thereafter, we will examine the structural underpinnings of bootstrapping and identify the
key elements that warrant consideration prior to reinvigorating the process through the use
of a theoretical exemplar. Finally, we will explore a potential implementation and utilize
this to elucidate the individual steps in what we term "plots".


